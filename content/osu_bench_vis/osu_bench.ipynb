{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport pandas as pd",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "osu_bench_np2_get = pd.read_csv(\"2023-07-21_weaver3_osu_bench_np2_get.csv\")\nosu_bench_np2_put = pd.read_csv(\"2023-07-21_weaver3_osu_bench_np2_put.csv\")\ndfs = [osu_bench_np2_get, osu_bench_np2_put]\nlabels = [\"osu_bench_np2_get\", \"osu_bench_np2_put\"]",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def figure_for_attribute(dfs,\n                         labels,\n                         attribute,\n                         xaxis=\"n\",\n                         xlabel=\"problem size (array of size n)\",\n                         ylabel = None,\n                         title = None,\n                         style=\"--\",\n                         scale=\"linear\",\n                         figsize=[8.25,4.95],\n                         colors=None):\n    color_defaults = [\"tab:purple\", \"tab:brown\", \"tab:red\", \"k\", \"g\", \"c\", \"tab:orange\", \"tab:blue\", \"y\"]\n    if colors is None:\n        colors = color_defaults[:len(dfs)]\n    \n    \n    if ylabel is None:\n        ylabel = attribute\n    \n    if title is None:\n        title = f\"update benchmark ({attribute.replace('_',' ')})\"\n    \n    if len(dfs) == 0:\n        print(\"required to have at least one line to plot\")\n    \n    maxy = max(dfs[0][f\"{attribute}-mean\"])\n    miny = min(dfs[0][f\"{attribute}-mean\"])\n    for df in dfs:\n        cur_max = max(df[f\"{attribute}-mean\"])\n        cur_min = min(df[f\"{attribute}-mean\"])\n        if cur_max > maxy:\n            maxy = cur_max\n        if cur_min < miny:\n            miny = cur_min\n    \n    if labels is None:\n        print(\"required to label each line\")\n        \n    plt.figure(figsize=figsize)\n    for df, dflabel,c in zip(dfs,labels,colors):\n        plt.plot(df[xaxis], df[f\"{attribute}-mean\"], style, label=dflabel, color=c)\n    plt.title(title)\n    plt.legend()\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    if type(scale) is str:\n        plt.xscale(scale)\n        plt.yscale(scale)\n    else:\n        plt.xscale(scale[0])\n        plt.yscale(scale[1])\n    if scale == \"linear\":\n        ylim_base = 0\n    else:\n        ylim_base = miny*0.95\n    plt.ylim(ylim_base,(maxy)*1.05)\n    plt.grid()\n    plt.savefig(f\"{title}.png\")\n    plt.show()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "figure_for_attribute(dfs, labels, \"message_rate\", \"message rate (GB/s)\", \"2-node rma osu benchmark message rate\", style=\"*-\", scale=\"log\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "figure_for_attribute(dfs, labels, \"time_latency\", \"message latency (microseconds)\", \"2-node rma osu benchmark message latency\", style=\"*-\", scale=\"log\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# 2023-07-26\n- Paper submission\n    - no extended abstract\n    - http://nowlab.cse.ohio-state.edu/espm2/ an option\n    - ISC?\n    - IPDPS?\n    - ExaMPI (SC)?\n- Year-round Internship logistics?\n    - If a student is supported by a project proposal, all good\n    - Otherwise, agreement is to work together with subcontract\n    - Otherwise, I would have to independently meet PhD requirements and Sandia requirements\n- OSU a true test?\n    - MPI fence is a synchronization (MPI barrier would be enough)\n    - fence is just memory ordering (Like the mailbox)\n        - So put fence isn't enough to synchronize processes\n    - Must barrier between processes\n    - (TODO: read nvshmem documentation especially nvshmem fence)\n        - This means the correct approach would be quiet barrier\n    - (PGAS is quite slow when it comes to measure this latency)\n    - If I was to implement a check after the send, it might not succeed\n    - To test: initialize the buffer to some value on the sender with a seed, 0 on receiver\n        - then do ping-pong, and check that the data is exactly the data we send\n        - So we will receive the zeroed data, maybe a little bit of the data we put in\n    - So with the latency, we might not actually be enqueueing them\n    - Documentation: https://docs.nvidia.com/nvshmem/archives/nvshmem-101/api/docs/gen/api/ordering.html\n    - += vs =\n        - If I don't have the opposite operation, I could just go to the next stage\n- A long discussion about Allreduce",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}